{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import h5py\n",
    "import pickle\n",
    "import torch\n",
    "import mygene\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import traceback\n",
    "import warnings\n",
    "import scanpy as sc\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \".\"\n",
    "HEST_DATA_DIR = os.path.join(BASE_DIR, \"hest_data\")\n",
    "ST_DIR = os.path.join(HEST_DATA_DIR, \"st\")\n",
    "PATCHES_DIR = os.path.join(HEST_DATA_DIR, \"patches\")\n",
    "VOCAB_PATH = os.path.join(BASE_DIR,\"whole_human_vocab.csv\")\n",
    "COMMON_GENES_PATH = os.path.join(BASE_DIR, \"common_overlap_genes.txt\")\n",
    "COMMON_SAMPLES_PATH = os.path.join(BASE_DIR, \"common_overlap_samples.txt\")\n",
    "FILE_NAMES_PATH = os.path.join(BASE_DIR, \"file_names.txt\")\n",
    "\n",
    "gene_vocab = pd.read_csv(VOCAB_PATH)\n",
    "genes_in_vocab = gene_vocab[\"SYMBOL\"]\n",
    "symbol_to_id = dict(zip(gene_vocab[\"SYMBOL\"], gene_vocab[\"ID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_files = [f for f in os.listdir(PATCHES_DIR) if f.endswith(\".h5\")]\n",
    "h5ad_files = [f for f in os.listdir(ST_DIR) if f.endswith(\".h5ad\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of files - h5 files : 649, h5ad files : 649\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current number of files - h5 files : {len(h5_files)}, h5ad files : {len(h5ad_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_with_GRCh = []\n",
    "files_with_ENSG = []\n",
    "\n",
    "for file in tqdm(h5ad_files):\n",
    "    file_path = os.path.join(ST_DIR, file)\n",
    "    \n",
    "    try:\n",
    "        adata = sc.read_h5ad(file_path)  \n",
    "        genes = set(adata.var_names) \n",
    "        \n",
    "        if any(gene.startswith(\"GRCh\") for gene in genes):\n",
    "            files_with_GRCh.append(file)\n",
    "\n",
    "        elif any(gene.startswith(\"ENSG\") for gene in genes):\n",
    "            files_with_ENSG.append(file)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "for file in tqdm(files_with_ENSG):\n",
    "    try:\n",
    "        file_path = os.path.join(ST_DIR, file)\n",
    "        adata = sc.read_h5ad(file_path)\n",
    "        \n",
    "        adata.var_names = adata.var_names.astype(str)\n",
    "        \n",
    "        # Extract Ensembl IDs\n",
    "        ensembl_ids = list(set(\n",
    "            gene.split(\".\")[0] \n",
    "            for gene in adata.var_names \n",
    "            if gene.startswith(\"ENSG\")\n",
    "        ))\n",
    "        \n",
    "        if not ensembl_ids:\n",
    "            print(f\"{file}: No ENSG genes found\")\n",
    "            continue\n",
    "        \n",
    "        # Query API\n",
    "        gene_info = mg.querymany(\n",
    "            ensembl_ids,\n",
    "            scopes=\"ensembl.gene\",\n",
    "            fields=\"symbol\",\n",
    "            species=\"human\",\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        ensembl_to_symbol = {\n",
    "            item['query']: item.get('symbol', item['query'])\n",
    "            for item in gene_info\n",
    "            if 'query' in item\n",
    "        }\n",
    "        \n",
    "        # Convert gene names\n",
    "        adata.var_names = [\n",
    "            ensembl_to_symbol.get(gene.split(\".\")[0], gene)\n",
    "            for gene in adata.var_names\n",
    "        ]\n",
    "        \n",
    "        adata.write_h5ad(file_path)\n",
    "        print(f\"{file}: Converted successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{file}: Error - {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files_with_GRCh:\n",
    "    try:\n",
    "        file_path = os.path.join(ST_DIR, file)\n",
    "        adata = sc.read_h5ad(file_path)\n",
    "\n",
    "        adata.var_names = adata.var_names.str.replace(r\"^GRCh38__+\", \"\", regex=True)\n",
    "\n",
    "        adata.write_h5ad(file_path)\n",
    "        print(f\"{file} Converted. Saved at: {file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{file} Error occured: {e}\")\n",
    "        traceback.print_exc() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check overlapping genes across samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_paths = [os.path.join(ST_DIR, file) for file in os.listdir(ST_DIR)]\n",
    "\n",
    "overlap_counts = {}\n",
    "overlap_genes = {}\n",
    "\n",
    "for file in tqdm(adata_paths):\n",
    "    try:\n",
    "        adata = sc.read_h5ad(file)\n",
    "        \n",
    "        gene_series = pd.Series(adata.var_names)\n",
    "        \n",
    "        unique_genes = gene_series[gene_series.map(gene_series.value_counts()) == 1].unique()\n",
    "        \n",
    "        overlapping_genes = pd.Index(unique_genes)[pd.Index(unique_genes).isin(genes_in_vocab)]\n",
    "        overlap_count = len(overlapping_genes)\n",
    "        \n",
    "        overlap_counts[file] = overlap_count\n",
    "        overlap_genes[file] = list(overlapping_genes)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{file} Error occured: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oc = pd.DataFrame(\n",
    "    overlap_counts.items(), \n",
    "    columns=[\"Files\", \"overlap_counts\"]\n",
    ")\n",
    "print(df_oc)\n",
    "\n",
    "file_paths = sorted(list(df_oc[df_oc[\"overlap_counts\"] >= 10000][\"Files\"]))\n",
    "file_names = [os.path.basename(file).split(\".\")[0] for file in file_paths]\n",
    "\n",
    "df_oc_sorted = df_oc.sort_values(by = 'overlap_counts', ascending = False)\n",
    "\n",
    "overlap_genes_filter = {}\n",
    "\n",
    "for file in tqdm(file_paths):\n",
    "    try:\n",
    "        adata = sc.read_h5ad(file)\n",
    "        gene_series = pd.Series(adata.var_names)\n",
    "\n",
    "        unique_genes = set(gene_series[gene_series.map(gene_series.value_counts()) == 1])\n",
    "        overlapping_genes = sorted(unique_genes.intersection(set(genes_in_vocab)))\n",
    "\n",
    "        overlap_genes_filter[file] = overlapping_genes\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{file} Error occured: {e}\")\n",
    "\n",
    "if overlap_genes_filter:\n",
    "    common_overlap_genes = set.intersection(*(set(genes) for genes in overlap_genes_filter.values()))\n",
    "else:\n",
    "    common_overlap_genes = set()\n",
    "\n",
    "with open(COMMON_GENES_PATH, \"w\", encoding = \"utf-8\") as file:\n",
    "    for gene in sorted(common_overlap_genes):\n",
    "        file.write(gene + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(COMMON_SAMPLES_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "    file_names = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "with open(COMMON_GENES_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "    common_overlap_genes = [line.strip() for line in file if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, scanpy as sc, h5py\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "h5ad_paths = [os.path.join(ST_DIR, sample + \".h5ad\") for sample in file_names]\n",
    "OUT_CSV   = \"./st_sentences/top100_sentences.csv\"\n",
    "\n",
    "sample_stats = []        \n",
    "total_nonzero = 0          \n",
    "total_cells = 0           \n",
    "header_written = False    \n",
    "\n",
    "for file in tqdm(h5ad_paths):\n",
    "    sample = os.path.basename(file).split(\".\")[0]\n",
    "    h5_file = os.path.join(PATCHES_DIR, sample + \".h5\")\n",
    "\n",
    "    with h5py.File(h5_file, \"r\") as h5_data:  \n",
    "        adata = sc.read_h5ad(file)\n",
    "        adata.var_names_make_unique()\n",
    "        adata = adata[:, adata.var.index.intersection(sorted(common_overlap_genes))]\n",
    "\n",
    "        h5_barcodes = h5_data[\"barcode\"][:].astype(str).reshape(-1)\n",
    "        adata_barcodes = np.array(adata.obs_names)\n",
    "\n",
    "        valid_indices = np.where(np.isin(adata_barcodes, h5_barcodes))[0]\n",
    "        adata = adata[valid_indices].copy()\n",
    "\n",
    "        adata = adata[np.array([np.where(adata_barcodes[valid_indices] == barcode)[0][0] for barcode in h5_barcodes])]\n",
    "\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "\n",
    "        X = csr_matrix(adata.X)\n",
    "        genes = adata.var.index.to_numpy()\n",
    "        barcodes = adata.obs.index.to_numpy()\n",
    "\n",
    "        nnz_per_cell = np.diff(X.indptr)           \n",
    "        if nnz_per_cell.size > 0:                  \n",
    "            sample_stats.append({                   \n",
    "                \"sample\": sample,\n",
    "                \"n_cells\": int(nnz_per_cell.size),\n",
    "                \"mean_nonzero_genes\": float(nnz_per_cell.mean()),\n",
    "                \"median_nonzero_genes\": float(np.median(nnz_per_cell)),\n",
    "                \"std_nonzero_genes\": float(nnz_per_cell.std()),\n",
    "            })\n",
    "            total_cells += int(nnz_per_cell.size)   \n",
    "            total_nonzero += int(nnz_per_cell.sum())\n",
    "\n",
    "        rows = []\n",
    "        for i in range(X.shape[0]):\n",
    "            row = X.getrow(i)\n",
    "            if row.nnz == 0:\n",
    "                continue\n",
    "            else:\n",
    "                nz_idx = row.indices\n",
    "                nz_val = row.data\n",
    "                order = np.argsort(-nz_val)\n",
    "                top_idx = nz_idx[order][:100]\n",
    "                top_genes = genes[top_idx]\n",
    "                sentence = \" \".join(top_genes)\n",
    "\n",
    "            rows.append({\"id\": f\"{sample}_{barcodes[i]}\", \"sentence\": sentence})\n",
    "\n",
    "        if rows:  \n",
    "            df_out = pd.DataFrame(rows, columns=[\"id\", \"sentence\"])\n",
    "            df_out.to_csv(OUT_CSV, mode=\"a\", index=False, header=(not header_written))\n",
    "            header_written = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_path = \"./st_sentences/top100_sentences.csv\"\n",
    "images_dir = \"./st_images\"\n",
    "\n",
    "spot_sentences = pd.read_csv(sentences_path)\n",
    "spot_image_files = os.listdir(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = set(spot_sentences['id'].astype(str))\n",
    "\n",
    "for img_file in spot_image_files:\n",
    "    if img_file.endswith(\".png\"):\n",
    "        sample_id = img_file.split(\".png\")[0]  \n",
    "        if sample_id not in valid_ids:\n",
    "            img_path = os.path.join(images_dir, img_file)\n",
    "            os.remove(img_path)\n",
    "            print(f\"Deleted: {img_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012725\n",
      "1012725\n"
     ]
    }
   ],
   "source": [
    "spot_image_files_ar = os.listdir(images_dir)\n",
    "print(len(spot_sentences))\n",
    "print(len(spot_image_files_ar))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st_lira_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
